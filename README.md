# üîç Review Sentiment Analyzer

<div align="center">

![Python](https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-0.109+-009688?style=for-the-badge&logo=fastapi&logoColor=white)
![Next.js](https://img.shields.io/badge/Next.js-16-000000?style=for-the-badge&logo=next.js&logoColor=white)
![TypeScript](https://img.shields.io/badge/TypeScript-5.0+-3178C6?style=for-the-badge&logo=typescript&logoColor=white)
![Redis](https://img.shields.io/badge/Redis-5.0+-DC382D?style=for-the-badge&logo=redis&logoColor=white)
![Tailwind CSS](https://img.shields.io/badge/Tailwind-4.0-06B6D4?style=for-the-badge&logo=tailwindcss&logoColor=white)

**A full-stack AI-powered application for scraping app reviews from multiple sources, performing sentiment analysis, and generating prioritized product backlogs.**

[Features](#-features) ‚Ä¢ [Tech Stack](#-tech-stack) ‚Ä¢ [Architecture](#-system-architecture) ‚Ä¢ [Quick Start](#-quick-start) ‚Ä¢ [API Docs](#-api-documentation) ‚Ä¢ [Screenshots](#-screenshots)

</div>

---

## üéØ Project Overview

This project solves the challenge of **understanding user sentiment at scale** by aggregating reviews from multiple platforms, analyzing them with AI, and converting insights into actionable product tasks.

### The Problem
- Product teams spend hours manually reading reviews across platforms
- Reviews are scattered across Google Play, App Store, Reddit, and forums
- Difficult to identify patterns and prioritize what to fix first

### The Solution
An end-to-end pipeline that:
1. **Scrapes** reviews from 4+ sources concurrently
2. **Analyzes** sentiment using Google Gemini AI
3. **Categorizes** findings (bugs, features, pain points, etc.)
4. **Prioritizes** tasks using MoSCoW or Lean methodologies
5. **Generates** a sprint-ready product backlog

---

## ‚ú® Features

### üîÑ Multi-Source Data Aggregation
- **Google Play Store** - App reviews with ratings, dates, and user info
- **Apple App Store** - iOS app reviews across 40+ countries
- **Reddit** - Subreddit discussions and user feedback
- **Google Search** - Web results for broader sentiment context

### ü§ñ AI-Powered Analysis
- **Google Gemini Integration** - Advanced LLM for sentiment analysis
- **Smart Categorization** - 7 finding types (bugs, features, pain points, etc.)
- **Pattern Recognition** - AI-discovered insights from review clusters
- **Confidence Scoring** - Reliability metrics for each finding

### ‚ö° Real-Time Processing
- **WebSocket Updates** - Live progress streaming to frontend
- **Async Architecture** - Non-blocking concurrent scraping
- **Task Persistence** - Redis-backed with 24-hour TTL
- **Progress Tracking** - Granular status updates per source

### üìã Product Prioritization
- **MoSCoW Framework** - Must/Should/Could/Won't categorization
- **Lean Methodology** - Value vs. effort scoring
- **Sprint Planning** - Budget and duration constraints
- **Actionable Backlog** - Ready-to-use task descriptions

### üé® Modern Frontend
- **Responsive UI** - Works on desktop and mobile
- **Dark/Light Theme** - Custom purple brand theme
- **Interactive Results** - Expandable categories and findings
- **Real-Time Feedback** - Progress bars and status updates

---

## üõ† Tech Stack

### Backend
| Technology | Purpose |
|------------|---------|
| **Python 3.10+** | Core language |
| **FastAPI** | High-performance async web framework |
| **Pydantic v2** | Data validation and serialization |
| **Redis** | Task queue and result caching |
| **httpx** | Async HTTP client for scraping |
| **BeautifulSoup4** | HTML parsing for Reddit |
| **Google Gemini** | AI sentiment analysis |
| **SerpAPI** | Google/App Store data extraction |
| **WebSockets** | Real-time progress updates |
| **Uvicorn** | ASGI server |

### Frontend
| Technology | Purpose |
|------------|---------|
| **Next.js 16** | React framework with App Router |
| **TypeScript** | Type-safe JavaScript |
| **Tailwind CSS v4** | Utility-first styling |
| **shadcn/ui** | Accessible component library |
| **React Hooks** | State management |

### DevOps & Tools
| Technology | Purpose |
|------------|---------|
| **Docker** | Containerization (planned) |
| **Vercel** | Frontend deployment |
| **Railway** | Backend deployment |
| **Git** | Version control |

---

## üèó System Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                              FRONTEND (Next.js)                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ AnalysisForm‚îÇ  ‚îÇProgressModal‚îÇ  ‚îÇ ResultsView ‚îÇ  ‚îÇPrioritizationResults‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ         ‚îÇ                ‚îÇ                ‚îÇ                     ‚îÇ            ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îÇ                                    ‚îÇ                                          ‚îÇ
‚îÇ                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                               ‚îÇ
‚îÇ                          ‚îÇ    API Client     ‚îÇ                               ‚îÇ
‚îÇ                          ‚îÇ  (lib/api.ts)     ‚îÇ                               ‚îÇ
‚îÇ                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                     ‚îÇ REST API / WebSocket
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                              BACKEND (FastAPI)                               ‚îÇ
‚îÇ                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                               ‚îÇ
‚îÇ                          ‚îÇ   API Endpoints   ‚îÇ                               ‚îÇ
‚îÇ                          ‚îÇ (scraper.py)      ‚îÇ                               ‚îÇ
‚îÇ                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                               ‚îÇ
‚îÇ                                    ‚îÇ                                          ‚îÇ
‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ    ‚îÇ                               ‚îÇ                               ‚îÇ         ‚îÇ
‚îÇ    ‚ñº                               ‚ñº                               ‚ñº         ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ ‚îÇGoogle    ‚îÇ  ‚îÇApple     ‚îÇ  ‚îÇReddit    ‚îÇ  ‚îÇGoogle    ‚îÇ  ‚îÇ  Prioritization  ‚îÇ‚îÇ
‚îÇ ‚îÇPlay      ‚îÇ  ‚îÇStore     ‚îÇ  ‚îÇScraper   ‚îÇ  ‚îÇSearch    ‚îÇ  ‚îÇ  Engine          ‚îÇ‚îÇ
‚îÇ ‚îÇScraper   ‚îÇ  ‚îÇScraper   ‚îÇ  ‚îÇ(httpx)   ‚îÇ  ‚îÇScraper   ‚îÇ  ‚îÇ  (MoSCoW/Lean)   ‚îÇ‚îÇ
‚îÇ ‚îÇ(SerpAPI) ‚îÇ  ‚îÇ(SerpAPI) ‚îÇ  ‚îÇ          ‚îÇ  ‚îÇ(SerpAPI) ‚îÇ  ‚îÇ                  ‚îÇ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îÇ      ‚îÇ             ‚îÇ             ‚îÇ             ‚îÇ                  ‚îÇ          ‚îÇ
‚îÇ      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ          ‚îÇ
‚îÇ                          ‚îÇ                                        ‚îÇ          ‚îÇ
‚îÇ                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                             ‚îÇ          ‚îÇ
‚îÇ                ‚îÇ   Data Processor  ‚îÇ                             ‚îÇ          ‚îÇ
‚îÇ                ‚îÇ   (Aggregation)   ‚îÇ                             ‚îÇ          ‚îÇ
‚îÇ                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                             ‚îÇ          ‚îÇ
‚îÇ                          ‚îÇ                                        ‚îÇ          ‚îÇ
‚îÇ                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ                ‚îÇ  Gemini AI        ‚îÇ              ‚îÇ       Redis           ‚îÇ ‚îÇ
‚îÇ                ‚îÇ  Sentiment Engine ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫  Task Storage         ‚îÇ ‚îÇ
‚îÇ                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ  (24hr TTL)           ‚îÇ ‚îÇ
‚îÇ                                                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                     ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚ñº                ‚ñº                ‚ñº
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ Google Play ‚îÇ  ‚îÇ App Store   ‚îÇ  ‚îÇ   Reddit    ‚îÇ
            ‚îÇ   API       ‚îÇ  ‚îÇ   API       ‚îÇ  ‚îÇ   Website   ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìÅ Project Structure

```
project-scrap/
‚îú‚îÄ‚îÄ app/                          # üêç BACKEND (FastAPI)
‚îÇ   ‚îú‚îÄ‚îÄ api/v1/endpoints/         # API route handlers
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scraper.py            # Main scraper endpoints
‚îÇ   ‚îú‚îÄ‚îÄ core/                     # Core infrastructure
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ redis_store.py        # Redis task persistence
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ connection_manager.py # WebSocket management
‚îÇ   ‚îú‚îÄ‚îÄ models/                   # Pydantic data models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ requests.py           # Request validation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ responses.py          # Response schemas
‚îÇ   ‚îú‚îÄ‚îÄ services/                 # Business logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ google_play.py        # Google Play scraper
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ apple_store.py        # Apple Store scraper
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ reddit.py             # Async Reddit scraper
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ google_search.py      # Google Search scraper
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sentiment.py          # Gemini sentiment analysis
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_processor.py     # Data aggregation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prioritization.py     # Task prioritization
‚îÇ   ‚îú‚îÄ‚îÄ utils/                    # Utility functions
‚îÇ   ‚îú‚îÄ‚îÄ config.py                 # Pydantic Settings
‚îÇ   ‚îî‚îÄ‚îÄ main.py                   # FastAPI app
‚îÇ
‚îú‚îÄ‚îÄ frontend/                     # ‚öõÔ∏è FRONTEND (Next.js)
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app/                  # App Router pages
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/           # React components
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ui/               # shadcn/ui components
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ AnalysisForm.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ResultsView.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hooks/                # Custom React hooks
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lib/                  # API client & utils
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ types/                # TypeScript interfaces
‚îÇ   ‚îî‚îÄ‚îÄ package.json
‚îÇ
‚îú‚îÄ‚îÄ logs/                         # Application logs
‚îú‚îÄ‚îÄ requirements.txt              # Python dependencies
‚îú‚îÄ‚îÄ run.py                        # Backend entry point
‚îî‚îÄ‚îÄ README.md                     # This file
```

---

## üöÄ Quick Start

### Prerequisites

- Python 3.10+
- Node.js 18+
- Redis server
- API keys: SerpAPI, Google Gemini

### Backend Setup

```bash
# Clone repository
git clone https://github.com/yourusername/review-sentiment-analyzer.git
cd review-sentiment-analyzer

# Create virtual environment
python -m venv venv
.\venv\Scripts\activate  # Windows
source venv/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env with your API keys

# Start Redis (Docker)
docker run -d -p 6379:6379 redis:alpine

# Run backend
python run.py
```

### Frontend Setup

```bash
# Navigate to frontend
cd frontend

# Install dependencies
npm install

# Configure environment
echo "NEXT_PUBLIC_API_URL=http://localhost:8000" > .env.local

# Run development server
npm run dev
```

### Access the Application

| Service | URL |
|---------|-----|
| Frontend | http://localhost:3000 |
| Backend API | http://localhost:8000 |
| Swagger Docs | http://localhost:8000/docs |
| ReDoc | http://localhost:8000/redoc |

---

## üì° API Documentation

### Core Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/v1/scrape` | Start multi-source scrape task |
| `GET` | `/api/v1/task/{task_id}` | Get task status and result |
| `POST` | `/api/v1/prioritize` | Prioritize findings from analysis |
| `WS` | `/ws/task/{task_id}` | WebSocket for real-time progress |

### Single-Source Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/v1/scrape/google-play` | Google Play only |
| `POST` | `/api/v1/scrape/apple-store` | Apple Store only |
| `POST` | `/api/v1/scrape/reddit` | Reddit only |
| `POST` | `/api/v1/scrape/google-search` | Google Search only |

### Example Request

```bash
curl -X POST http://localhost:8000/api/v1/scrape \
  -H "Content-Type: application/json" \
  -d '{
    "product_name": "Spotify",
    "google_play": {
      "product_id": "com.spotify.music",
      "platform": "phone"
    },
    "apple_store": {
      "product_id": "324684580",
      "country": "us"
    },
    "include_reddit": true,
    "include_google_search": true
  }'
```

---

## üìä Analysis Categories

The AI categorizes findings into 7 actionable types:

| Type | Icon | Description | Example |
|------|------|-------------|---------|
| `bug` | üêõ | Technical issues, crashes | "App crashes when uploading photos" |
| `feature_request` | ‚ú® | User-requested features | "Please add dark mode" |
| `requirement` | üìã | Must-have missing features | "Need offline support" |
| `usability_friction` | üîß | UX issues | "Navigation is confusing" |
| `pain_point` | üò§ | User frustrations | "Too many ads" |
| `positive_review` | ‚≠ê | Things users love | "Best app for podcasts!" |
| `ai_insight` | ü§ñ | AI-discovered patterns | "30% of users mention slow loading" |

---

## üì∏ Screenshots

> *Add screenshots of your application here*

| Analysis Form | Results View | Prioritization |
|---------------|--------------|----------------|
| Step 1 form | Categorized findings | Sprint backlog |

---

## ‚öôÔ∏è Configuration

### Environment Variables

| Variable | Required | Default | Description |
|----------|----------|---------|-------------|
| `SERPAPI_KEY` | ‚úÖ | - | SerpAPI key for scraping |
| `GEMINI_API_KEY` | ‚úÖ | - | Google Gemini API key |
| `REDIS_URL` | ‚ùå | `redis://localhost:6379` | Redis connection URL |
| `HOST` | ‚ùå | `0.0.0.0` | Server host |
| `PORT` | ‚ùå | `8000` | Server port |
| `DEBUG` | ‚ùå | `false` | Enable debug mode |
| `NEXT_PUBLIC_API_URL` | ‚úÖ | - | Backend URL for frontend |

---

## üéì Skills Demonstrated

This project showcases proficiency in:

### Backend Development
- ‚úÖ Building RESTful APIs with FastAPI
- ‚úÖ Async/await patterns with Python asyncio
- ‚úÖ WebSocket implementation for real-time updates
- ‚úÖ Data validation with Pydantic v2
- ‚úÖ Redis integration for caching and persistence
- ‚úÖ External API integration (SerpAPI, Gemini)
- ‚úÖ Web scraping with httpx and BeautifulSoup

### Frontend Development
- ‚úÖ Modern React with Next.js 16 App Router
- ‚úÖ TypeScript for type safety
- ‚úÖ State management with React hooks
- ‚úÖ Component-based architecture
- ‚úÖ Responsive design with Tailwind CSS
- ‚úÖ API integration and error handling

### System Design
- ‚úÖ Microservices architecture
- ‚úÖ Async task processing
- ‚úÖ Real-time communication patterns
- ‚úÖ Caching strategies
- ‚úÖ Clean code and separation of concerns

### AI/ML Integration
- ‚úÖ LLM integration (Google Gemini)
- ‚úÖ Prompt engineering for sentiment analysis
- ‚úÖ Structured output parsing

---

## üîÆ Roadmap

- [ ] **Docker & Compose** - Containerized deployment
- [ ] **pytest Suite** - Unit and integration tests
- [ ] **GitHub Actions CI** - Automated testing
- [ ] **API Authentication** - JWT/API key auth
- [ ] **Rate Limiting** - Request throttling
- [ ] **Caching Layer** - Response caching
- [ ] **Export Features** - CSV/PDF export
- [ ] **Multi-language** - i18n support

---

## üìö Documentation

| Document | Description |
|----------|-------------|
| [Backend README](app/README.md) | FastAPI server documentation |
| [Frontend README](frontend/README.md) | Next.js application documentation |

---

## ü§ù Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

<div align="center">

**Built with ‚ù§Ô∏è using FastAPI, Next.js, and Google Gemini**

‚≠ê Star this repo if you find it useful!

</div>
